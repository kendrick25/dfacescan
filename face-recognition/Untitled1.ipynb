{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7f32672-2916-41ee-a14c-d0a6144aca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import os\n",
    "from deepface import DeepFace\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_pixels_from_image(image: np.ndarray, facial_area: dict) -> np.ndarray:\n",
    "    x, y, w, h = facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h']\n",
    "    x = max(0, x)\n",
    "    y = max(0, y)\n",
    "    face_crop = image[y:y+h, x:x+w]\n",
    "    face_crop_float64 = face_crop.astype(np.float64) / 255.0\n",
    "    return face_crop_float64\n",
    "\n",
    "def extract_and_expand_faces(img_path: str, margin_ratio: float = 0.0) -> list:\n",
    "    image = cv2.imread(img_path)\n",
    "    faces = DeepFace.extract_faces(\n",
    "        img_path=image,\n",
    "        detector_backend='retinaface',\n",
    "        enforce_detection=False\n",
    "    )\n",
    "\n",
    "    for face_data in faces:\n",
    "        facial_area = face_data['facial_area']\n",
    "        x, y, w, h = facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h']\n",
    "        margin_x = int(w * margin_ratio)\n",
    "        margin_y = int(h * margin_ratio)\n",
    "        facial_area['x'] = x - margin_x\n",
    "        facial_area['y'] = y - margin_y\n",
    "        facial_area['w'] = w + 2 * margin_x\n",
    "        facial_area['h'] = h + 2 * margin_y\n",
    "\n",
    "    for __face__ in faces:\n",
    "        __face__['face'] = extract_pixels_from_image(image, __face__['facial_area'])\n",
    "    \n",
    "    return faces\n",
    "\n",
    "def get_people_list(path_people_ref: str) -> list:\n",
    "    ref_directory = path_people_ref\n",
    "    list_dict = []\n",
    "    for person_name in os.listdir(ref_directory):\n",
    "        person_path = os.path.join(ref_directory, person_name)\n",
    "        if os.path.isdir(person_path):\n",
    "            images = [img for img in os.listdir(person_path) if img.endswith(\".png\")]\n",
    "            image_paths = [os.path.join(person_path, img).replace(\"\\\\\", \"/\") for img in images]\n",
    "            person_dict = {\n",
    "                \"name\": person_name,\n",
    "                \"images\": images,\n",
    "                \"images_paths\": image_paths\n",
    "            }\n",
    "            list_dict.append(person_dict)\n",
    "    return list_dict\n",
    "\n",
    "list_dict_people = get_people_list(\"./data/classroom/ref/\")\n",
    "\n",
    "def recognize_person(analyze_faces: list, ref_face: list, metric_model_name: str = \"Facenet512\", \n",
    "                     metric_distance: str = \"cosine\", metric_threshold: float = 0.44) -> list:\n",
    "    if not ref_face or len(ref_face) == 0:\n",
    "        print(\"Error: The reference face is empty.\")\n",
    "        return []\n",
    "\n",
    "    target_face_data = ref_face[0]\n",
    "    target_face = target_face_data['face']\n",
    "    array_bgr_target_face = (target_face * 255.0).astype(np.uint8)\n",
    "\n",
    "    results = []\n",
    "    total_faces = len(analyze_faces)\n",
    "\n",
    "    for i, face_data in enumerate(analyze_faces):\n",
    "        loading = f\"\\rProcessing... {i + 1}/{total_faces} comparisons ({((i + 1) / total_faces) * 100:.2f}%)\"\n",
    "        print(loading, end=\"\")\n",
    "\n",
    "        facial_area = face_data['facial_area']\n",
    "        face = face_data['face']\n",
    "        array_bgr_face = (face * 255.0).astype(np.uint8)\n",
    "\n",
    "        result = DeepFace.verify(\n",
    "            img1_path=array_bgr_target_face,\n",
    "            img2_path=array_bgr_face,\n",
    "            detector_backend=\"skip\",\n",
    "            model_name=metric_model_name,\n",
    "            distance_metric=metric_distance,\n",
    "            threshold=metric_threshold,\n",
    "            enforce_detection=False\n",
    "        )\n",
    "\n",
    "        results.append({\n",
    "            \"index\": i,\n",
    "            \"distance\": result['distance'],\n",
    "            \"threshold\": result['threshold'],\n",
    "            \"verified\": result['verified'],\n",
    "            \"facial_area\": facial_area\n",
    "        })\n",
    "\n",
    "    results.sort(key=lambda x: x['distance'])\n",
    "    return results\n",
    "\n",
    "def draw_verified_faces(image, result_list_dict, name_person=\"target\"):\n",
    "    total_faces = len(result_list_dict)\n",
    "    comparison_counter = 0\n",
    "    for result in result_list_dict:\n",
    "        facial_area = result['facial_area']\n",
    "        x, y, w, h = facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h']\n",
    "\n",
    "        if result['verified']:\n",
    "            color = (0, 255, 0)\n",
    "            confidence = 1.0 - result['distance']\n",
    "            label = f\"{name_person} ({confidence:.2f}%)\"\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(image, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "        comparison_counter += 1\n",
    "        progress = (comparison_counter / total_faces) * 100\n",
    "        print(f\"\\rProcessing faces... {comparison_counter}/{total_faces} ({progress:.2f}%)\", end=\"\")\n",
    "\n",
    "    print(\"\\nFinished drawing verified faces.\")\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81b0c6f5-ff47-49dd-80a6-0bc6d2ce6c6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "img must be numpy array or str but it is <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 89\u001b[0m\n\u001b[0;32m     86\u001b[0m      \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo faces verified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 89\u001b[0m  \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 67\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     64\u001b[0m analyze_image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/classroom/analyze/test_image.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Ruta de imagen a analizar\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Cargar las caras de referencia (lista de rostros de personas conocidas)\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m ref_face_list \u001b[38;5;241m=\u001b[39m \u001b[43mextract_and_expand_faces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmargin_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Cargar las caras a analizar\u001b[39;00m\n\u001b[0;32m     70\u001b[0m analyze_faces \u001b[38;5;241m=\u001b[39m extract_and_expand_faces(analyze_image_path, margin_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 21\u001b[0m, in \u001b[0;36mextract_and_expand_faces\u001b[1;34m(img_path, margin_ratio)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_and_expand_faces\u001b[39m(img_path: \u001b[38;5;28mstr\u001b[39m, margin_ratio: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m     20\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path)\n\u001b[1;32m---> 21\u001b[0m     faces \u001b[38;5;241m=\u001b[39m \u001b[43mDeepFace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_faces\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mretinaface\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m face_data \u001b[38;5;129;01min\u001b[39;00m faces:\n\u001b[0;32m     28\u001b[0m         facial_area \u001b[38;5;241m=\u001b[39m face_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfacial_area\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\.conda\\envs\\flow\\lib\\site-packages\\deepface\\DeepFace.py:549\u001b[0m, in \u001b[0;36mextract_faces\u001b[1;34m(img_path, detector_backend, enforce_detection, align, expand_percentage, grayscale, color_face, normalize_face, anti_spoofing)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_faces\u001b[39m(\n\u001b[0;32m    490\u001b[0m     img_path: Union[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray],\n\u001b[0;32m    491\u001b[0m     detector_backend: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopencv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    498\u001b[0m     anti_spoofing: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    499\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m    500\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;124;03m    Extract faces from a given image\u001b[39;00m\n\u001b[0;32m    502\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;124;03m            just available in the result only if anti_spoofing is set to True in input arguments.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 549\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdetection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_faces\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_detection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrayscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrayscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_face\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_face\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalize_face\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize_face\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43manti_spoofing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manti_spoofing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\flow\\lib\\site-packages\\deepface\\modules\\detection.py:83\u001b[0m, in \u001b[0;36mextract_faces\u001b[1;34m(img_path, detector_backend, enforce_detection, align, expand_percentage, grayscale, color_face, normalize_face, anti_spoofing)\u001b[0m\n\u001b[0;32m     80\u001b[0m resp_objs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# img might be path, base64 or numpy array. Convert it to numpy whatever it is.\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m img, img_name \u001b[38;5;241m=\u001b[39m \u001b[43mimage_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException while loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\flow\\lib\\site-packages\\deepface\\commons\\image_utils.py:81\u001b[0m, in \u001b[0;36mload_image\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     78\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(img)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg must be numpy array or str but it is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(img)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# The image is a base64 string\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mValueError\u001b[0m: img must be numpy array or str but it is <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "   def handle_face_collisions(analyze_faces, ref_face_list, person_name):\n",
    "    comparison_counter = 0\n",
    "    total_comparisons = len(analyze_faces) * len(ref_face_list)\n",
    "    results = []\n",
    "\n",
    "    for analyze_face in analyze_faces:\n",
    "        for ref_face in ref_face_list:\n",
    "            # Convertir las imágenes de las caras en arrays BGR para la comparación\n",
    "            array_bgr_target_face = ref_face[\"face\"]\n",
    "            array_bgr_face = analyze_face[\"face\"]\n",
    "\n",
    "            # Primera comparación con umbral bajo\n",
    "            initial_result = DeepFace.verify(\n",
    "                img1_path=array_bgr_target_face,\n",
    "                img2_path=array_bgr_face,\n",
    "                detector_backend=\"skip\",\n",
    "                model_name=metric_model_name,\n",
    "                distance_metric=metric_distance,\n",
    "                threshold=initial_threshold,\n",
    "                enforce_detection=False\n",
    "            )\n",
    "\n",
    "            # Si la primera comparación es positiva, se realiza la comparación final\n",
    "            if initial_result['verified']:\n",
    "                # Segunda comparación con umbral alto\n",
    "                final_result = DeepFace.verify(\n",
    "                    img1_path=array_bgr_target_face,\n",
    "                    img2_path=array_bgr_face,\n",
    "                    detector_backend=\"skip\",\n",
    "                    model_name=metric_model_name,\n",
    "                    distance_metric=metric_distance,\n",
    "                    threshold=final_threshold,\n",
    "                    enforce_detection=False\n",
    "                )\n",
    "\n",
    "                # Almacenar el resultado de la comparación final\n",
    "                if final_result['verified']:\n",
    "                    results.append({\n",
    "                        \"person\": person_name,\n",
    "                        \"index\": comparison_counter,\n",
    "                        \"distance\": final_result['distance'],\n",
    "                        \"threshold\": final_result['threshold'],\n",
    "                        \"verified\": final_result['verified'],\n",
    "                        \"facial_area\": analyze_face['facial_area'],\n",
    "                        \"confidence\": 1.0 - final_result['distance']  # Proporción de confianza\n",
    "                    })\n",
    "\n",
    "            # Actualización del contador de comparaciones\n",
    "            comparison_counter += 1\n",
    "            # Calculamos el porcentaje de progreso\n",
    "            progress = (comparison_counter / total_comparisons) * 100\n",
    "            print(f\"\\rProcessing... {comparison_counter}/{total_comparisons} comparisons ({progress:.2f}%)\", end=\"\")\n",
    "\n",
    "    print(\"\\nFinished processing all face comparisons.\")\n",
    "    \n",
    "    # Ordenar los resultados por la distancia (menor es mejor)\n",
    "    results.sort(key=lambda x: x['distance'])\n",
    "\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    # Ruta de la imagen de referencia y la lista de imágenes a analizar\n",
    "    ref_image_path = \"./data/classroom/ref/person_1.jpg\"  # Ruta de ejemplo\n",
    "    analyze_image_path = \"./data/classroom/analyze/test_image.jpg\"  # Ruta de imagen a analizar\n",
    "\n",
    "    # Cargar las caras de referencia (lista de rostros de personas conocidas)\n",
    "    ref_face_list = extract_and_expand_faces(ref_image_path, margin_ratio=0.2)\n",
    "\n",
    "    # Cargar las caras a analizar\n",
    "    analyze_faces = extract_and_expand_faces(analyze_image_path, margin_ratio=0.2)\n",
    "\n",
    "    # Realizar la comparación de rostros\n",
    "    results = handle_face_collisions(analyze_faces, ref_face_list, \"person_1\")\n",
    "\n",
    "    # Si se encontraron coincidencias, dibujarlas en la imagen original\n",
    "    if results:\n",
    "        image = cv2.imread(analyze_image_path)\n",
    "        image_with_faces = draw_verified_faces(image, results, \"person_1\")\n",
    "\n",
    "        # Guardar la imagen con los rostros verificados\n",
    "        output_image_path = \"./output/test_result.jpg\"\n",
    "        cv2.imwrite(output_image_path, image_with_faces)\n",
    "\n",
    "        print(f\"Processed image saved to {output_image_path}\")\n",
    "    else:\n",
    "        print(\"No faces verified.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841db68c-5a3c-4e93-b8ec-226b80808704",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
