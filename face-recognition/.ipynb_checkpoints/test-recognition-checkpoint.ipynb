{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2152ec70-78c0-417f-a931-aa8b77d304de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.15 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:19) [MSC v.1929 64 bit (AMD64)]\n",
      "1.26.4\n",
      "2.10.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from deepface import DeepFace\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "print(sys.version)\n",
    "print(np.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72edd2a0-ac68-47a4-89c6-93007d77e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pixels_from_image(image: np.ndarray, facial_area: dict) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extrae el área de la imagen basado en las coordenadas de 'facial_area' y devuelve\n",
    "    el recorte como un array en formato float64.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): Imagen original cargada con OpenCV en formato uint8 BGR.\n",
    "        facial_area (dict): Diccionario con las coordenadas 'x', 'y', 'w', 'h'.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: El recorte del rostro en formato float64 y en el rango [0, 1].\n",
    "    \"\"\"\n",
    "    x, y, w, h = facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h']\n",
    "    \n",
    "    # Ajustar las coordenadas para evitar índices negativos\n",
    "    x = max(0, x)\n",
    "    y = max(0, y)\n",
    "    \n",
    "    # Recortar la imagen en la región del área facial\n",
    "    face_crop = image[y:y+h, x:x+w]\n",
    "\n",
    "    # Convertir el recorte a float64 y escalar a [0, 1]\n",
    "    face_crop_float64 = face_crop.astype(np.float64) / 255.0\n",
    "    \n",
    "    return face_crop_float64\n",
    "\n",
    "def extract_and_expand_faces(img_path: str, margin_ratio: float = 0.0) -> list:\n",
    "    \"\"\"\n",
    "    Extrae rostros de una imagen y expande los bounding boxes según el margin_ratio.\n",
    "    Args:\n",
    "        img_path (str): Ruta de la imagen para procesar.\n",
    "        margin_ratio (float): Proporción de expansión del bounding box. \n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: Lista de rostros detectados con bounding boxes ajustados.\n",
    "    \"\"\"\n",
    "    # Cargar la imagen\n",
    "    image = cv2.imread(img_path)\n",
    "\n",
    "    # Detectar rostros con DeepFace usando el modelo RetinaFace\n",
    "    faces = DeepFace.extract_faces(\n",
    "        img_path=image,\n",
    "        detector_backend='retinaface',\n",
    "        enforce_detection=False\n",
    "    )\n",
    "\n",
    "    # Expande los bounding boxes\n",
    "    for face_data in faces:\n",
    "        facial_area = face_data['facial_area']\n",
    "        \n",
    "        # Obtener coordenadas originales\n",
    "        x, y, w, h = facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h']\n",
    "        \n",
    "        # Calcular margen adicional basado en el ratio\n",
    "        margin_x = int(w * margin_ratio)\n",
    "        margin_y = int(h * margin_ratio)\n",
    "        \n",
    "        # Expande el bounding box con el margen calculado\n",
    "        facial_area['x'] = x - margin_x\n",
    "        facial_area['y'] = y - margin_y\n",
    "        facial_area['w'] = w + 2 * margin_x\n",
    "        facial_area['h'] = h + 2 * margin_y\n",
    "\n",
    "    for __face__ in faces:\n",
    "        __face__['face'] = extract_pixels_from_image(image, __face__['facial_area'])\n",
    "    \n",
    "    return faces\n",
    "\n",
    "def get_img_array_uint8(arraydata):\n",
    "    img = arraydata\n",
    "    #B, G, R = img.T\n",
    "    #__bgr_img = np.array((B, G, R)).T\n",
    "    #bgr_img = (__bgr_img*255).astype(np.uint8)\n",
    "    bgr_img = (img*255).astype(np.uint8)\n",
    "    return bgr_img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
